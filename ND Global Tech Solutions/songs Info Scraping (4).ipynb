{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "req=requests.get(\"https://www.lyricstape.com/movie-directory\")\n",
    "soup =BeautifulSoup(req.content,\"html.parser\")\n",
    "print(soup.prettify())\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "movie_names={\n",
    "    'movies':[] }\n",
    "div_properties = {'class':'col-sm-3','style': 'background-color:#f9f9f9;margin:10px;'} \n",
    "div_elements = soup.find_all('div', attrs=div_properties)\n",
    "for movie in soup.find_all('div',attrs=div_properties):\n",
    "    link_text = movie.text\n",
    "    movie_names['movies'].append(link_text)\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.DataFrame(movie_names)\n",
    "df\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "URL=[]\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rows = soup.find_all(class_=\"panel-group\")\n",
    "# Extract and print the URLs\n",
    "for row in rows:\n",
    "    links = row.find_all(\"a\")\n",
    "    for link in links:\n",
    "        href = link.get(\"href\")\n",
    "        if href:\n",
    "            URL.append(href)\n",
    "            print(href)\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "URL\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df['URL']=URL\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "songs_list_url=[]\n",
    "for i in URL:\n",
    "    req=requests.get(i)\n",
    "    soup =BeautifulSoup(req.content,\"html.parser\")\n",
    "    song_url=soup.find_all(id=\"song_title\")\n",
    "    for song in song_url:\n",
    "        links=song.find_all(\"a\")\n",
    "        for link in links:\n",
    "            href = link.get(\"href\")\n",
    "        if href:\n",
    "            songs_list_url.append(href)\n",
    "            print(href)\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "songs=[]\n",
    "for i in URL:\n",
    "    req=requests.get(i)\n",
    "    soup =BeautifulSoup(req.content,\"html.parser\")\n",
    "    span_element = soup.find('span', class_='frb-description')\n",
    "    for song_name in soup.find_all('span', class_='frb-description'):\n",
    "        song=song_name.text\n",
    "        songs.append(song)\n",
    "        print(song)\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "songs\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df1=pd.DataFrame(songs,columns=['songs'])\n",
    "df1\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df1['songs URL']=songs_list_url\n",
    "df1\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df1.to_csv(r\"C:\\Users\\NACHI\\Desktop\\movie song details scraping\\song_details.csv\")\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lyrics=[]\n",
    "for i in URL:\n",
    "    req=requests.get(i)\n",
    "    soup =BeautifulSoup(req.content,\"html.parser\")\n",
    "    lyricist_span=soup.find('span',id=\"lyricistname\")\n",
    "    lyricist_name = lyricist_span.get_text()\n",
    "    print(lyricist_name)\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "singers=[]\n",
    "for i in URL:\n",
    "    req=requests.get(i)\n",
    "    soup =BeautifulSoup(req.content,\"html.parser\")\n",
    "    singers_span=soup.find('span',id=\"signarname\")\n",
    "    singers_name = singers_span.get_text()\n",
    "    print(singers_name)\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    ""
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 }
}